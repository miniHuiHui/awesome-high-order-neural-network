# Awesome High-Order Neural Networks

This repository focuses on high-order neural network architecture in computer vision.

We start with Attention-mechanisms, to Transformers, Element-wise Multiplication.

* Our works.

## Attentions

## Transfomers

[ICLR2021] [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929.pdf)

[ICML2021] [Training data-efficient image transformers & distillation through attention](https://arxiv.org/pdf/2012.12877.pdf)

[ICCV2021] [Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf)

## Element-wise Multiplication ConvNets

### Quadratic Neural Networks

[ICCV2017] [SORT: Second-Order Response Transform for Visual Recognition](https://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_SORT_Second-Order_Response_ICCV_2017_paper.pdf)

* [ASP-DAC2024] [QuadraNet: Improving High-Order Neural Interaction Efficiency with Hardware-Aware Quadratic Neural Networks](https://ieeexplore.ieee.org/abstract/document/10473936)

* [arxiv 2024] [QuadraNet V2: Efficient and Sustainable Training of High-Order Neural Networks with Quadratic Adaptation](https://arxiv.org/abs/2405.03192)


### Polynomial and High-Order Neural Networks

[TPAMI2021] [Deep Polynomial Neural Networks](https://ieeexplore.ieee.org/abstract/document/9353253?casa_token=ky0Wzm7kKykAAAAA:50GXi3hNogt2uFIGk4QmtjgE2iROmIkV4TKOCpspo5MPYBqUpcB3W_s1s3naUlWmN5hbR3CKsA)

[CVPR2020] [P-nets: Deep Polynomial Neural Networks](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chrysos_P-nets_Deep_Polynomial_Neural_Networks_CVPR_2020_paper.pdf)

[ECCV2022] [Augmenting Deep Classifiers with Polynomial Neural Networks](https://link.springer.com/content/pdf/10.1007/978-3-031-19806-9_40.pdf?pdf=inline%20link)

[ICLR2022] [The Spectral Bias of Polynomial Neural Networks](https://openreview.net/pdf?id=P7FLfMLTSEX)

[NeurIPS2022] [Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a Polynomial Net Study](https://openreview.net/pdf?id=_cXUMAnWJJj)

[NeurIPS2022] [HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions](https://arxiv.org/pdf/2207.14284.pdf)

[arxiv2022] [Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition](https://arxiv.org/pdf/2211.11943.pdf)

[NeurIPS2022] [Focal Modulation Networks](https://proceedings.neurips.cc/paper_files/paper/2022/file/1b08f585b0171b74d1401a5195e986f1-Paper-Conference.pdf)

[CVPR2024] [Rewrite the Stars](https://arxiv.org/pdf/2403.19967)

* [NeurIPS 2024] [Infinite-dimensional Feature Interaction](https://arxiv.org/abs/2405.13972)

### Kernel Neural Networks

[CVPR2019] [Kervolutional Neural Networks](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Kervolutional_Neural_Networks_CVPR_2019_paper.pdf)

## Bilinear Pooling

[ICCV2017] [Factorized Bilinear Models for Image Recognition](https://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Factorized_Bilinear_Models_ICCV_2017_paper.pdf)

[CVPR2019] [Global Second-order Pooling Convolutional Networks](https://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Global_Second-Order_Pooling_Convolutional_Networks_CVPR_2019_paper.pdf)

[TNNLS2021] [Detachable Second-Order Pooling: Toward High-Performance First-Order Networks](https://ieeexplore.ieee.org/abstract/document/9343714?casa_token=lUbtc3DOS5UAAAAA:ei-dpTN3-wtwNp0zj2LF2dOepPmX7r0MnKfN8mZVejWSES-5Hw1aZIBHRnhnpPO2NP70d_eBwA)

[NeurIPS2019] [Deep Multimodal Multilinear Fusion with High-order Polynomial Pooling](https://proceedings.neurips.cc/paper/2019/hash/f56d8183992b6c54c92c16a8519a6e2b-Abstract.html)


## Computation Library

* [MLSys2022] [QuadraLib: A Performant Quadratic Neural Network Library for Architecture Optimization and Design Exploration](https://proceedings.mlsys.org/paper/2022/file/a5bfc9e07964f8dddeb95fc584cd965d-Paper.pdf)

## Related Scholar:

[Grigorios G Chrysos](https://grigorisg9gr.github.io/#)

[Feng-Lei Fan](https://fengleifan.github.io/Feng-Lei.Fan.github.io/)




